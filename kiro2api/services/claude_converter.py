"""
Claude API è¯·æ±‚è½¬æ¢å™¨
å°† Claude API è¯·æ±‚è½¬æ¢ä¸º CodeWhisperer API è¯·æ±‚
ä¸ request_builder.py (OpenAIæ ¼å¼) å‘é€çš„å­—æ®µå®Œå…¨ä¸€è‡´
"""

import re
import json
import uuid
import copy
import base64
import logging
from typing import List, Dict, Any, Optional

from config import MODEL_MAP, DEFAULT_MODEL, PROFILE_ARN
from models.claude_schemas import ClaudeRequest, ClaudeMessage

logger = logging.getLogger(__name__)


def map_claude_model_to_codewhisperer(claude_model: str) -> str:
    """
    å°† Claude æ¨¡å‹åç§°æ˜ å°„åˆ° CodeWhisperer æ¨¡å‹
    å®Œå…¨åŸºäº config.py ä¸­çš„ MODEL_MAP é…ç½®ï¼Œåªæ”¯æŒç²¾ç¡®åŒ¹é…
    """
    # ç²¾ç¡®åŒ¹é…
    if claude_model in MODEL_MAP:
        logger.info(f"âœ… æ¨¡å‹åŒ¹é…: {claude_model} -> {MODEL_MAP[claude_model]}")
        return MODEL_MAP[claude_model]
    
    # ä½¿ç”¨é»˜è®¤æ¨¡å‹
    default_value = MODEL_MAP.get(DEFAULT_MODEL)
    if default_value:
        logger.info(f"âš ï¸ æ¨¡å‹æœªåŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤å€¼: {claude_model} -> {default_value}")
        return default_value
    
    # æœ€åçš„å…œåº•
    logger.error(f"âŒ æ— æ³•æ˜ å°„æ¨¡å‹: {claude_model}")
    raise ValueError(f"No model mapping available for: {claude_model}")


def extract_text_from_claude_content(content) -> str:
    """ä» Claude å†…å®¹ä¸­æå–æ–‡æœ¬"""
    if content is None:
        return ""
    if isinstance(content, str):
        return content
    if isinstance(content, list):
        text_parts = []
        for block in content:
            if isinstance(block, dict):
                if block.get("type") == "text":
                    text_parts.append(block.get("text", ""))
                elif block.get("type") == "tool_result":
                    result_content = block.get("content", "")
                    if isinstance(result_content, str):
                        text_parts.append(result_content)
                    elif isinstance(result_content, list):
                        for item in result_content:
                            if isinstance(item, dict) and item.get("type") == "text":
                                text_parts.append(item.get("text", ""))
            elif hasattr(block, "type"):
                if block.type == "text":
                    text_parts.append(block.text)
        return "".join(text_parts)
    return str(content) if content else ""


def extract_images_from_claude_content(content) -> List[Dict[str, Any]]:
    """ä» Claude å†…å®¹ä¸­æå–å›¾ç‰‡ï¼Œè½¬æ¢ä¸º CodeWhisperer æ ¼å¼"""
    images = []
    if not isinstance(content, list):
        return images
    
    for block in content:
        if isinstance(block, dict) and block.get("type") == "image":
            source = block.get("source", {})
            if source.get("type") == "base64":
                media_type = source.get("media_type", "image/png")
                match = re.search(r'image/(\w+)', media_type)
                if match:
                    image_format = match.group(1)
                    encoded_data = source.get("data", "")
                    
                    # éªŒè¯ Base64 ç¼–ç 
                    try:
                        base64.b64decode(encoded_data)
                        images.append({
                            "format": image_format,
                            "source": {"bytes": encoded_data}
                        })
                        logger.info(f"ğŸ–¼ï¸ æˆåŠŸå¤„ç†å›¾ç‰‡ï¼Œæ ¼å¼: {image_format}, å¤§å°: {len(encoded_data)} å­—ç¬¦")
                    except Exception as e:
                        logger.error(f"âŒ Base64 ç¼–ç æ— æ•ˆ: {e}")
    
    return images


def convert_claude_to_codewhisperer_request(request: ClaudeRequest) -> Dict[str, Any]:
    """
    å°† Claude API è¯·æ±‚è½¬æ¢ä¸º CodeWhisperer API è¯·æ±‚
    ä¸ request_builder.py (OpenAIæ ¼å¼) å‘é€çš„å­—æ®µå®Œå…¨ä¸€è‡´
    """
    logger.info(f"ğŸ”„ request model: {request.model}")
    codewhisperer_model = map_claude_model_to_codewhisperer(request.model)
    conversation_id = str(uuid.uuid4())
    
    # æå– system prompt
    system_prompt = ""
    if request.system:
        if isinstance(request.system, str):
            system_prompt = request.system
        elif isinstance(request.system, list):
            system_parts = []
            for block in request.system:
                if hasattr(block, "type") and block.type == "text":
                    system_parts.append(block.text)
                elif isinstance(block, dict) and block.get("type") == "text":
                    system_parts.append(block.get("text", ""))
            system_prompt = "\n".join(system_parts)
    
    # è½¬æ¢æ¶ˆæ¯ä¸ºç±»ä¼¼ OpenAI æ ¼å¼çš„å¤„ç†
    conversation_messages = []
    for msg in request.messages:
        conversation_messages.append(msg)
    
    if not conversation_messages:
        raise ValueError("No conversation messages found")
    
    # æ„å»ºå†å²è®°å½• - ä¸ OpenAI æ ¼å¼å®Œå…¨ä¸€è‡´
    history = []
    
    if len(conversation_messages) > 1:
        history_messages = conversation_messages[:-1]
        
        # å¤„ç†å†å²æ¶ˆæ¯
        processed_messages = []
        i = 0
        while i < len(history_messages):
            msg = history_messages[i]
            
            if msg.role == "user":
                content = extract_text_from_claude_content(msg.content) or "Continue"
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å« tool_result
                if isinstance(msg.content, list):
                    tool_results = []
                    text_parts = []
                    for block in msg.content:
                        if isinstance(block, dict):
                            if block.get("type") == "tool_result":
                                tool_use_id = block.get("tool_use_id", "unknown")
                                result_content = block.get("content", "")
                                if isinstance(result_content, str):
                                    tool_results.append(f"[Tool result for {tool_use_id}]: {result_content}")
                                elif isinstance(result_content, list):
                                    result_text = "".join([
                                        item.get("text", "") for item in result_content 
                                        if isinstance(item, dict) and item.get("type") == "text"
                                    ])
                                    tool_results.append(f"[Tool result for {tool_use_id}]: {result_text}")
                            elif block.get("type") == "text":
                                text_parts.append(block.get("text", ""))
                    
                    if tool_results:
                        content = "\n".join(tool_results)
                        if text_parts:
                            content += "\n" + "".join(text_parts)
                
                processed_messages.append(("user", content))
                i += 1
            
            elif msg.role == "assistant":
                # æ£€æŸ¥æ˜¯å¦åŒ…å« tool_use
                if isinstance(msg.content, list):
                    tool_descriptions = []
                    text_content = ""
                    for block in msg.content:
                        if isinstance(block, dict):
                            if block.get("type") == "tool_use":
                                func_name = block.get("name", "unknown")
                                args = json.dumps(block.get("input", {}))
                                tool_descriptions.append(f"[Called {func_name} with args: {args}]")
                            elif block.get("type") == "text":
                                text_content += block.get("text", "")
                    
                    if tool_descriptions:
                        content = " ".join(tool_descriptions)
                        logger.info(f"ğŸ“Œ Processing assistant message with tool calls: {content}")
                    else:
                        content = text_content or "I understand."
                else:
                    content = extract_text_from_claude_content(msg.content) or "I understand."
                
                processed_messages.append(("assistant", content))
                i += 1
            else:
                i += 1
        
        # æ„å»ºå†å²è®°å½•å¯¹ - ä¸ OpenAI æ ¼å¼å®Œå…¨ä¸€è‡´
        i = 0
        while i < len(processed_messages):
            role, content = processed_messages[i]
            
            if role == "user":
                history.append({
                    "userInputMessage": {
                        "content": content,
                        "modelId": codewhisperer_model,
                        "origin": "AI_EDITOR"
                    }
                })
                
                # æŸ¥æ‰¾åŠ©æ‰‹å“åº”
                if i + 1 < len(processed_messages) and processed_messages[i + 1][0] == "assistant":
                    _, assistant_content = processed_messages[i + 1]
                    history.append({
                        "assistantResponseMessage": {
                            "content": assistant_content
                        }
                    })
                    i += 2
                else:
                    # æ²¡æœ‰åŠ©æ‰‹å“åº”ï¼Œæ·»åŠ å ä½ç¬¦
                    history.append({
                        "assistantResponseMessage": {
                            "content": "I understand."
                        }
                    })
                    i += 1
            elif role == "assistant":
                # å­¤ç«‹çš„åŠ©æ‰‹æ¶ˆæ¯
                history.append({
                    "userInputMessage": {
                        "content": "Continue",
                        "modelId": codewhisperer_model,
                        "origin": "AI_EDITOR"
                    }
                })
                history.append({
                    "assistantResponseMessage": {
                        "content": content
                    }
                })
                i += 1
            else:
                i += 1
    
    # æ„å»ºå½“å‰æ¶ˆæ¯
    current_message = conversation_messages[-1]
    
    # å¤„ç†å½“å‰æ¶ˆæ¯ä¸­çš„å›¾ç‰‡
    images = extract_images_from_claude_content(current_message.content)
    
    # è·å–å½“å‰æ¶ˆæ¯å†…å®¹
    current_content = extract_text_from_claude_content(current_message.content)
    
    # å¤„ç†ä¸åŒè§’è‰²çš„å½“å‰æ¶ˆæ¯ - ä¸ OpenAI æ ¼å¼ä¸€è‡´
    if current_message.role == "user":
        # æ£€æŸ¥æ˜¯å¦åŒ…å« tool_result
        if isinstance(current_message.content, list):
            tool_results = []
            text_parts = []
            for block in current_message.content:
                if isinstance(block, dict):
                    if block.get("type") == "tool_result":
                        tool_use_id = block.get("tool_use_id", "unknown")
                        result_content = block.get("content", "")
                        if isinstance(result_content, str):
                            tool_results.append(f"[Tool execution completed for {tool_use_id}]: {result_content}")
                        elif isinstance(result_content, list):
                            result_text = "".join([
                                item.get("text", "") for item in result_content 
                                if isinstance(item, dict) and item.get("type") == "text"
                            ])
                            tool_results.append(f"[Tool execution completed for {tool_use_id}]: {result_text}")
                    elif block.get("type") == "text":
                        text_parts.append(block.get("text", ""))
            
            if tool_results:
                current_content = "\n".join(tool_results)
                if text_parts:
                    current_content += "\n" + "".join(text_parts)
    
    elif current_message.role == "assistant":
        # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”åŒ…å« tool_use
        if isinstance(current_message.content, list):
            tool_descriptions = []
            for block in current_message.content:
                if isinstance(block, dict) and block.get("type") == "tool_use":
                    func_name = block.get("name", "unknown")
                    tool_descriptions.append(f"Continue after calling {func_name}")
            if tool_descriptions:
                current_content = "; ".join(tool_descriptions)
            else:
                current_content = "Continue the conversation"
        else:
            current_content = "Continue the conversation"
    
    # ç¡®ä¿å½“å‰æ¶ˆæ¯æœ‰å†…å®¹
    if not current_content:
        current_content = "Continue"
    
    # æ·»åŠ  system prompt åˆ°å½“å‰æ¶ˆæ¯ - ä¸ OpenAI æ ¼å¼ä¸€è‡´
    if system_prompt:
        current_content = f"{system_prompt}\n\n{current_content}"
    
    # æ„å»ºè¯·æ±‚ - ä¸ OpenAI æ ¼å¼å®Œå…¨ä¸€è‡´
    codewhisperer_request = {
        "profileArn": PROFILE_ARN,
        "conversationState": {
            "chatTriggerType": "MANUAL",
            "conversationId": conversation_id,
            "currentMessage": {
                "userInputMessage": {
                    "content": current_content,
                    "modelId": codewhisperer_model,
                    "origin": "AI_EDITOR"
                }
            },
            "history": history
        }
    }
    
    # æ·»åŠ å·¥å…·ä¸Šä¸‹æ–‡ - ä¸ OpenAI æ ¼å¼ä¸€è‡´
    user_input_message_context = {}
    if request.tools:
        user_input_message_context["tools"] = [
            {
                "toolSpecification": {
                    "name": tool.name,
                    "description": tool.description or "",
                    "inputSchema": {"json": tool.input_schema or {}}
                }
            } for tool in request.tools
        ]
    
    # æ·»åŠ å›¾ç‰‡ - ä¸ OpenAI æ ¼å¼ä¸€è‡´
    if images:
        codewhisperer_request["conversationState"]["currentMessage"]["userInputMessage"]["images"] = images
        logger.info(f"ğŸ“Š æ·»åŠ äº† {len(images)} ä¸ªå›¾ç‰‡åˆ° userInputMessage ä¸­")
        for idx, img in enumerate(images):
            logger.info(f"  - å›¾ç‰‡ {idx+1}: æ ¼å¼={img['format']}, å¤§å°={len(img['source']['bytes'])} å­—ç¬¦")
            logger.info(f"  - å›¾ç‰‡æ•°æ®å‰20å­—ç¬¦: {img['source']['bytes'][:20]}...")
        logger.info(f"âœ… æˆåŠŸæ·»åŠ  images åˆ° userInputMessage ä¸­")
    
    if user_input_message_context:
        codewhisperer_request["conversationState"]["currentMessage"]["userInputMessage"]["userInputMessageContext"] = user_input_message_context
        logger.info(f"âœ… æˆåŠŸæ·»åŠ  userInputMessageContext åˆ°è¯·æ±‚ä¸­")
    
    # åˆ›å»ºæ—¥å¿—è¯·æ±‚å‰¯æœ¬
    log_request = copy.deepcopy(codewhisperer_request)
    if "images" in log_request.get("conversationState", {}).get("currentMessage", {}).get("userInputMessage", {}):
        for img in log_request["conversationState"]["currentMessage"]["userInputMessage"]["images"]:
            if "bytes" in img.get("source", {}):
                img["source"]["bytes"] = img["source"]["bytes"][:20] + "..."
    
    logger.info(f"ğŸ”„ COMPLETE CODEWHISPERER REQUEST: {json.dumps(log_request, indent=2)}")
    return codewhisperer_request
