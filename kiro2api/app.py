import os
import json
import time
import uuid
import httpx
import re
import asyncio
import xml.etree.ElementTree as ET
import logging
import struct
import base64
import copy
from fastapi import FastAPI, HTTPException, Request, Header, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Union
from dotenv import load_dotenv
from json_repair import repair_json

# Configure logging
logging.basicConfig(level=logging.INFO) # for dev
# logging.basicConfig(level=logging.WARNING) 
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Initialize FastAPI app
app = FastAPI(
    title="Ki2API - Claude Sonnet 4 OpenAI Compatible API",
    description="OpenAI-compatible API for Claude Sonnet 4 via AWS CodeWhisperer",
    version="3.0.1"
)

# Configuration
API_KEY = os.getenv("API_KEY", "ki2api-key-2024")
KIRO_ACCESS_TOKEN = os.getenv("KIRO_ACCESS_TOKEN")
KIRO_REFRESH_TOKEN = os.getenv("KIRO_REFRESH_TOKEN")
KIRO_BASE_URL = "https://codewhisperer.us-east-1.amazonaws.com/generateAssistantResponse"
PROFILE_ARN = "arn:aws:codewhisperer:us-east-1:699475941385:profile/EHGA3GRVQMUK"

# Model mapping
MODEL_MAP = {
    "claude-sonnet-4-5-20250929": "CLAUDE_SONNET_4_5_20250929_V1_0",
    "claude-3-5-haiku-20241022":  "auto",
    "claude-opus-4.5":"claude-opus-4.5"
}
DEFAULT_MODEL = "claude-sonnet-4-5-20250929"

# Pydantic models for OpenAI compatibility
class ImageUrl(BaseModel):
    url: str
    detail: Optional[str] = "auto"

class ContentPart(BaseModel):
    type: str
    text: Optional[str] = None
    image_url: Optional[ImageUrl] = None

class ToolCall(BaseModel):
    id: str
    type: str = "function"
    function: Dict[str, Any]
class ChatMessage(BaseModel):
    role: str
    content: Union[str, List[ContentPart], None]
    tool_calls: Optional[List[ToolCall]] = None
    tool_call_id: Optional[str] = None  # ç”¨äº tool è§’è‰²çš„æ¶ˆæ¯
    
    def get_content_text(self) -> str:
        """Extract text content from either string or content parts"""
        # Handle None content
        if self.content is None:
            logger.warning(f"Message with role '{self.role}' has None content")
            return ""
            
        if isinstance(self.content, str):
            return self.content
        elif isinstance(self.content, list):
            text_parts = []
            for part in self.content:
                if isinstance(part, dict):
                    if part.get("type") == "text" and "text" in part:
                        text_parts.append(part.get("text", ""))
                    elif part.get("type") == "tool_result" and "content" in part:
                        text_parts.append(part.get("content", ""))
                elif hasattr(part, 'text') and part.text:
                    text_parts.append(part.text)
            return "".join(text_parts)
        else:
            logger.warning(f"Unexpected content type: {type(self.content)}")
            return str(self.content) if self.content else ""

class Function(BaseModel):
    name: str
    description: Optional[str] = None
    parameters: Optional[Dict[str, Any]] = None

class Tool(BaseModel):
    type: str = "function"
    function: Function



class ChatCompletionRequest(BaseModel):
    model: str
    messages: List[ChatMessage]
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = 4000
    stream: Optional[bool] = False
    top_p: Optional[float] = 1.0
    frequency_penalty: Optional[float] = 0.0
    presence_penalty: Optional[float] = 0.0
    stop: Optional[Union[str, List[str]]] = None
    user: Optional[str] = None
    tools: Optional[List[Tool]] = None
    tool_choice: Optional[Union[str, Dict[str, Any]]] = "auto"

class Usage(BaseModel):
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
    prompt_tokens_details: Optional[Dict[str, int]] = Field(default_factory=lambda: {"cached_tokens": 0})
    completion_tokens_details: Optional[Dict[str, int]] = Field(default_factory=lambda: {"reasoning_tokens": 0})

class ResponseMessage(BaseModel):
    role: str
    content: Optional[str] = None
    tool_calls: Optional[List[ToolCall]] = None

class Choice(BaseModel):
    index: int
    message: ResponseMessage
    logprobs: Optional[Any] = None
    finish_reason: str

class StreamChoice(BaseModel):
    index: int
    delta: Dict[str, Any]
    logprobs: Optional[Any] = None
    finish_reason: Optional[str] = None

class ChatCompletionResponse(BaseModel):
    id: str = Field(default_factory=lambda: f"chatcmpl-{uuid.uuid4()}")
    object: str = "chat.completion"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    system_fingerprint: Optional[str] = "fp_ki2api_v3"
    choices: List[Choice]
    usage: Usage

class ChatCompletionStreamResponse(BaseModel):
    id: str = Field(default_factory=lambda: f"chatcmpl-{uuid.uuid4()}")
    object: str = "chat.completion.chunk"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    system_fingerprint: Optional[str] = "fp_ki2api_v3"
    choices: List[StreamChoice]
    usage: Optional[Usage] = None

class ErrorResponse(BaseModel):
    error: Dict[str, Any]

# Authentication
async def verify_api_key(authorization: str = Header(None)):
    if not authorization:
        raise HTTPException(
            status_code=401,
            detail={
                "error": {
                    "message": "You didn't provide an API key.",
                    "type": "invalid_request_error",
                    "param": None,
                    "code": "invalid_api_key"
                }
            }
        )
    
    if not authorization.startswith("Bearer "):
        raise HTTPException(
            status_code=401,
            detail={
                "error": {
                    "message": "Invalid API key format. Expected 'Bearer <key>'",
                    "type": "invalid_request_error",
                    "param": None,
                    "code": "invalid_api_key"
                }
            }
        )
    
    api_key = authorization.replace("Bearer ", "")
    if api_key != API_KEY:
        raise HTTPException(
            status_code=401,
            detail={
                "error": {
                    "message": "Invalid API key provided",
                    "type": "invalid_request_error",
                    "param": None,
                    "code": "invalid_api_key"
                }
            }
        )
    return api_key

# Token management
class TokenManager:
    def __init__(self):
        self.access_token = KIRO_ACCESS_TOKEN
        self.refresh_token = KIRO_REFRESH_TOKEN
        self.refresh_url = "https://prod.us-east-1.auth.desktop.kiro.dev/refreshToken"
        self.last_refresh_time = 0
        self.refresh_lock = asyncio.Lock()

    async def refresh_tokens(self):
        """åˆ·æ–°tokenï¼Œä½¿ç”¨é”é˜²æ­¢å¹¶å‘åˆ·æ–°è¯·æ±‚"""
        if not self.refresh_token:
            logger.error("æ²¡æœ‰åˆ·æ–°tokenï¼Œæ— æ³•åˆ·æ–°è®¿é—®token")
            return None
        
        async with self.refresh_lock:
            # æ£€æŸ¥æ˜¯å¦åœ¨çŸ­æ—¶é—´å†…å·²ç»åˆ·æ–°è¿‡
            current_time = time.time()
            if current_time - self.last_refresh_time < 5:
                logger.info("æœ€è¿‘å·²åˆ·æ–°tokenï¼Œä½¿ç”¨ç°æœ‰token")
                return self.access_token
            
            try:
                logger.info("å¼€å§‹åˆ·æ–°token...")
                async with httpx.AsyncClient() as client:
                    response = await client.post(
                        self.refresh_url,
                        json={"refreshToken": self.refresh_token},
                        timeout=30
                    )
                    response.raise_for_status()
                    
                    data = response.json()
                    if "accessToken" not in data:
                        logger.error(f"åˆ·æ–°tokenå“åº”ä¸­æ²¡æœ‰accessToken: {data}")
                        return None
                    
                    self.access_token = data.get("accessToken")
                    self.last_refresh_time = current_time
                    logger.info("tokenåˆ·æ–°æˆåŠŸ")
                    
                    # æ›´æ–°ç¯å¢ƒå˜é‡
                    os.environ["KIRO_ACCESS_TOKEN"] = self.access_token
                    
                    return self.access_token
            except Exception as e:
                logger.error(f"tokenåˆ·æ–°å¤±è´¥: {str(e)}")
                return None

    def get_token(self):
        return self.access_token

token_manager = TokenManager()

# XML Tool Call Parser (from version 1)
def parse_xml_tool_calls(response_text: str) -> Optional[List[ToolCall]]:
    """è§£æCodeWhispererè¿”å›çš„XMLæ ¼å¼å·¥å…·è°ƒç”¨ï¼Œè½¬æ¢ä¸ºOpenAIæ ¼å¼"""
    if not response_text:
        return None
    
    tool_calls = []
    
    logger.info(f"ğŸ” å¼€å§‹è§£æXMLå·¥å…·è°ƒç”¨ï¼Œå“åº”æ–‡æœ¬é•¿åº¦: {len(response_text)}")
    
    # æ–¹æ³•1: è§£æ <tool_use> æ ‡ç­¾æ ¼å¼
    tool_use_pattern = r'<tool_use>\s*<tool_name>([^<]+)</tool_name>\s*<tool_parameter_name>([^<]+)</tool_parameter_name>\s*<tool_parameter_value>([^<]*)</tool_parameter_value>\s*</tool_use>'
    matches = re.finditer(tool_use_pattern, response_text, re.DOTALL | re.IGNORECASE)
    
    for match in matches:
        function_name = match.group(1).strip()
        param_name = match.group(2).strip()
        param_value = match.group(3).strip()
        
        arguments = {param_name: param_value}
        tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
        
        tool_call = ToolCall(
            id=tool_call_id,
            type="function",
            function={
                "name": function_name,
                "arguments": json.dumps(arguments, ensure_ascii=False)
            }
        )
        tool_calls.append(tool_call)
        logger.info(f"âœ… è§£æåˆ°å·¥å…·è°ƒç”¨: {function_name} with {param_name}={param_value}")
    
    # æ–¹æ³•2: è§£æç®€å•çš„ <tool_name> æ ¼å¼
    if not tool_calls:
        simple_pattern = r'<tool_name>([^<]+)</tool_name>\s*<tool_parameter_name>([^<]+)</tool_parameter_name>\s*<tool_parameter_value>([^<]*)</tool_parameter_value>'
        matches = re.finditer(simple_pattern, response_text, re.DOTALL | re.IGNORECASE)
        
        for match in matches:
            function_name = match.group(1).strip()
            param_name = match.group(2).strip()
            param_value = match.group(3).strip()
            
            arguments = {param_name: param_value}
            tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
            
            tool_call = ToolCall(
                id=tool_call_id,
                type="function",
                function={
                    "name": function_name,
                    "arguments": json.dumps(arguments, ensure_ascii=False)
                }
            )
            tool_calls.append(tool_call)
            logger.info(f"âœ… è§£æåˆ°ç®€å•å·¥å…·è°ƒç”¨: {function_name} with {param_name}={param_value}")
    
    # æ–¹æ³•3: è§£æåªæœ‰å·¥å…·åçš„æƒ…å†µ
    if not tool_calls:
        name_only_pattern = r'<tool_name>([^<]+)</tool_name>'
        matches = re.finditer(name_only_pattern, response_text, re.IGNORECASE)
        
        for match in matches:
            function_name = match.group(1).strip()
            tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
            
            tool_call = ToolCall(
                id=tool_call_id,
                type="function",
                function={
                    "name": function_name,
                    "arguments": "{}"
                }
            )
            tool_calls.append(tool_call)
            logger.info(f"âœ… è§£æåˆ°æ— å‚æ•°å·¥å…·è°ƒç”¨: {function_name}")
    
    if tool_calls:
        logger.info(f"ğŸ‰ æ€»å…±è§£æå‡º {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
        return tool_calls
    else:
        logger.info("âŒ æœªå‘ç°ä»»ä½•XMLæ ¼å¼çš„å·¥å…·è°ƒç”¨")
        return None

def find_matching_bracket(text: str, start_pos: int) -> int:
    """æ‰¾åˆ°åŒ¹é…çš„ç»“æŸæ‹¬å·ä½ç½®ï¼Œæ­£ç¡®å¤„ç†åµŒå¥—æ‹¬å·å’Œå­—ç¬¦ä¸²å†…çš„æ‹¬å·"""
    if not text or start_pos >= len(text) or text[start_pos] != '[':
        return -1
    
    bracket_count = 1
    in_string = False
    escape_next = False
    
    for i in range(start_pos + 1, len(text)):
        char = text[i]
        
        if escape_next:
            escape_next = False
            continue
        
        if char == '\\' and in_string:
            escape_next = True
            continue
        
        if char == '"' and not escape_next:
            in_string = not in_string
            continue
        
        if not in_string:
            if char == '[':
                bracket_count += 1
            elif char == ']':
                bracket_count -= 1
                if bracket_count == 0:
                    return i
    
    return -1

def parse_single_tool_call_professional(tool_call_text: str) -> Optional[ToolCall]:
      """ä¸“ä¸šçš„å·¥å…·è°ƒç”¨è§£æå™¨ - ä½¿ç”¨json_repairåº“"""
      logger.info(f"ğŸ”§ å¼€å§‹è§£æå·¥å…·è°ƒç”¨æ–‡æœ¬ (é•¿åº¦: {len(tool_call_text)})")

      # æ­¥éª¤1: æå–å‡½æ•°å
      name_pattern = r'\[Called\s+(\w+)\s+with\s+args:'
      name_match = re.search(name_pattern, tool_call_text, re.IGNORECASE)

      if not name_match:
          logger.warning("âš ï¸ æ— æ³•ä»æ–‡æœ¬ä¸­æå–å‡½æ•°å")
          return None

      function_name = name_match.group(1).strip()
      logger.info(f"âœ… æå–åˆ°å‡½æ•°å: {function_name}")

      # æ­¥éª¤2: æå–JSONå‚æ•°éƒ¨åˆ†
      # æ‰¾åˆ° "with args:" ä¹‹åçš„ä½ç½®
      args_start_marker = "with args:"
      args_start_pos = tool_call_text.lower().find(args_start_marker.lower())
      if args_start_pos == -1:
          logger.error("âŒ æ‰¾ä¸åˆ° 'with args:' æ ‡è®°")
          return None

      # ä» "with args:" åå¼€å§‹
      args_start = args_start_pos + len(args_start_marker)

      # æ‰¾åˆ°æœ€åçš„ ']'
      args_end = tool_call_text.rfind(']')
      if args_end <= args_start:
          logger.error("âŒ æ‰¾ä¸åˆ°ç»“æŸçš„ ']'")
          return None

      # æå–å¯èƒ½åŒ…å«JSONçš„éƒ¨åˆ†
      json_candidate = tool_call_text[args_start:args_end].strip()
      logger.info(f"ğŸ“ æå–çš„JSONå€™é€‰æ–‡æœ¬é•¿åº¦: {len(json_candidate)}")

      # æ­¥éª¤3: ä¿®å¤å¹¶è§£æJSON
      try:
          # ä½¿ç”¨json_repairä¿®å¤å¯èƒ½æŸåçš„JSON
          repaired_json = repair_json(json_candidate)
          logger.info(f"ğŸ”§ JSONä¿®å¤å®Œæˆï¼Œä¿®å¤åé•¿åº¦: {len(repaired_json)}")

          # è§£æä¿®å¤åçš„JSON
          parsed_args = json.loads(repaired_json)
          logger.info(f"âœ… JSONè§£ææˆåŠŸï¼Œç±»å‹: {type(parsed_args)}")

          # Handle both dictionary and list formats
          if isinstance(parsed_args, dict):
              # Original format: direct dictionary
              arguments = parsed_args
          elif isinstance(parsed_args, list) and len(parsed_args) > 0:
              # New format: list with arguments as first element
              if isinstance(parsed_args[0], dict):
                  arguments = parsed_args[0]
              else:
                  logger.error(f"âŒ åˆ—è¡¨æ ¼å¼ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ ä¸æ˜¯å­—å…¸: {type(parsed_args[0])}")
                  return None
          else:
              logger.error(f"âŒ è§£æç»“æœæ ¼å¼ä¸æ”¯æŒ: {type(parsed_args)}")
              return None

          # åˆ›å»ºå·¥å…·è°ƒç”¨å¯¹è±¡
          tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
          tool_call = ToolCall(
              id=tool_call_id,
              type="function",
              function={
                  "name": function_name,
                  "arguments": json.dumps(arguments, ensure_ascii=False)
              }
          )

          logger.info(f"âœ… æˆåŠŸåˆ›å»ºå·¥å…·è°ƒç”¨: {function_name} (å‚æ•°é”®: {list(arguments.keys())})")
          return tool_call

      except Exception as e:
          logger.error(f"âŒ JSONä¿®å¤/è§£æå¤±è´¥: {type(e).__name__}: {str(e)}")

          # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•æ›´æ¿€è¿›çš„ä¿®å¤
          try:
              # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
              first_brace = json_candidate.find('{')
              last_brace = json_candidate.rfind('}')

              if first_brace != -1 and last_brace > first_brace:
                  core_json = json_candidate[first_brace:last_brace + 1]

                  # å†æ¬¡å°è¯•ä¿®å¤
                  repaired_core = repair_json(core_json)
                  parsed_args = json.loads(repaired_core)

                  # Handle both dictionary and list formats in backup method too
                  if isinstance(parsed_args, dict):
                      arguments = parsed_args
                  elif isinstance(parsed_args, list) and len(parsed_args) > 0 and isinstance(parsed_args[0], dict):
                      arguments = parsed_args[0]
                  else:
                      logger.error(f"âŒ å¤‡ç”¨æ–¹æ¡ˆè§£æç»“æœæ ¼å¼ä¸æ”¯æŒ: {type(parsed_args)}")
                      return None

                  tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
                  tool_call = ToolCall(
                      id=tool_call_id,
                      type="function",
                      function={
                          "name": function_name,
                          "arguments": json.dumps(arguments, ensure_ascii=False)
                      }
                  )
                  logger.info(f"âœ… å¤‡ç”¨æ–¹æ¡ˆæˆåŠŸ: {function_name}")
                  return tool_call

          except Exception as backup_error:
              logger.error(f"âŒ å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥äº†: {backup_error}")

          return None

def parse_bracket_tool_calls_professional(response_text: str) -> Optional[List[ToolCall]]:
    """ä¸“ä¸šçš„æ‰¹é‡å·¥å…·è°ƒç”¨è§£æå™¨"""
    if not response_text or "[Called" not in response_text:
        logger.info("ğŸ“­ å“åº”æ–‡æœ¬ä¸­æ²¡æœ‰å·¥å…·è°ƒç”¨æ ‡è®°")
        return None
    
    tool_calls = []
    errors = []
    
    # æ–¹æ³•1: ä½¿ç”¨æ”¹è¿›çš„åˆ†å‰²æ–¹æ³•
    try:
        # æ‰¾åˆ°æ‰€æœ‰ [Called çš„ä½ç½®
        call_positions = []
        start = 0
        while True:
            pos = response_text.find("[Called", start)
            if pos == -1:
                break
            call_positions.append(pos)
            start = pos + 1
        
        logger.info(f"ğŸ” æ‰¾åˆ° {len(call_positions)} ä¸ªæ½œåœ¨çš„å·¥å…·è°ƒç”¨")
        
        for i, start_pos in enumerate(call_positions):
            # ç¡®å®šè¿™ä¸ªå·¥å…·è°ƒç”¨çš„ç»“æŸä½ç½®
            # å¯èƒ½æ˜¯ä¸‹ä¸€ä¸ª [Called çš„ä½ç½®ï¼Œæˆ–è€…æ–‡æœ¬ç»“æŸ
            if i + 1 < len(call_positions):
                end_search_limit = call_positions[i + 1]
            else:
                end_search_limit = len(response_text)
            
            # åœ¨é™å®šèŒƒå›´å†…æŸ¥æ‰¾ç»“æŸçš„ ]
            segment = response_text[start_pos:end_search_limit]
            
            # æŸ¥æ‰¾åŒ¹é…çš„ç»“æŸæ‹¬å·
            bracket_count = 0
            end_pos = -1
            
            for j, char in enumerate(segment):
                if char == '[':
                    bracket_count += 1
                elif char == ']':
                    bracket_count -= 1
                    if bracket_count == 0:
                        end_pos = start_pos + j
                        break
            
            if end_pos == -1:
                # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„æ‹¬å·ï¼Œå°è¯•æ‰¾æœ€åä¸€ä¸ª ]
                last_bracket = segment.rfind(']')
                if last_bracket != -1:
                    end_pos = start_pos + last_bracket
                else:
                    logger.warning(f"âš ï¸ å·¥å…·è°ƒç”¨ {i+1} æ²¡æœ‰æ‰¾åˆ°ç»“æŸæ‹¬å·")
                    continue
            
            # æå–å·¥å…·è°ƒç”¨æ–‡æœ¬
            tool_call_text = response_text[start_pos:end_pos + 1]
            logger.info(f"ğŸ“‹ æå–å·¥å…·è°ƒç”¨ {i+1}, é•¿åº¦: {len(tool_call_text)}")
            
            # è§£æå•ä¸ªå·¥å…·è°ƒç”¨
            parsed_call = parse_single_tool_call_professional(tool_call_text)
            if parsed_call:
                tool_calls.append(parsed_call)
            else:
                errors.append(f"å·¥å…·è°ƒç”¨ {i+1} è§£æå¤±è´¥")
                
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡è§£æè¿‡ç¨‹å‡ºé”™: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
    
    # è®°å½•ç»“æœ
    if tool_calls:
        logger.info(f"ğŸ‰ æˆåŠŸè§£æ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
        for tc in tool_calls:
            logger.info(f"  âœ“ {tc.function['name']} (ID: {tc.id})")
    
    if errors:
        logger.warning(f"âš ï¸ æœ‰ {len(errors)} ä¸ªè§£æå¤±è´¥:")
        for error in errors:
            logger.warning(f"  âœ— {error}")
    
    return tool_calls if tool_calls else None

# ä¸ºäº†ç¡®ä¿å…¼å®¹æ€§ï¼Œä¹Ÿæ›´æ–°åŸæ¥çš„å‡½æ•°å
def parse_bracket_tool_calls(response_text: str) -> Optional[List[ToolCall]]:
    """å‘åå…¼å®¹çš„å‡½æ•°å"""
    return parse_bracket_tool_calls_professional(response_text)

def parse_single_tool_call(tool_call_text: str) -> Optional[ToolCall]:
    """å‘åå…¼å®¹çš„å‡½æ•°å"""
    return parse_single_tool_call_professional(tool_call_text)

# Add deduplication function
def deduplicate_tool_calls(tool_calls: List[Union[Dict, ToolCall]]) -> List[ToolCall]:
    """Deduplicate tool calls based on function name and arguments"""
    seen = set()
    unique_tool_calls = []
    
    for tool_call in tool_calls:
        # Convert to ToolCall if it's a dict
        if isinstance(tool_call, dict):
            tc = ToolCall(
                id=tool_call.get("id", f"call_{uuid.uuid4().hex[:8]}"),
                type=tool_call.get("type", "function"),
                function=tool_call.get("function", {})
            )
        else:
            tc = tool_call
        
        # Create unique key based on function name and arguments
        key = (
            tc.function.get("name", ""),
            tc.function.get("arguments", "")
        )
        
        if key not in seen:
            seen.add(key)
            unique_tool_calls.append(tc)
        else:
            logger.info(f"ğŸ”„ Skipping duplicate tool call: {tc.function.get('name', 'unknown')}")
    
    return unique_tool_calls

def build_codewhisperer_request(request: ChatCompletionRequest):
    logger.info(f"ğŸ”„ request model: {request.model}")
    codewhisperer_model = MODEL_MAP.get(request.model, MODEL_MAP[DEFAULT_MODEL])
    conversation_id = str(uuid.uuid4())
    
    # Extract system prompt and user messages
    system_prompt = ""
    conversation_messages = []
    
    for msg in request.messages:
        if msg.role == "system":
            system_prompt = msg.get_content_text()
        elif msg.role in ["user", "assistant", "tool"]:
            conversation_messages.append(msg)
    
    if not conversation_messages:
        raise HTTPException(
            status_code=400, 
            detail={
                "error": {
                    "message": "No conversation messages found",
                    "type": "invalid_request_error",
                    "param": "messages",
                    "code": "invalid_request"
                }
            }
        )
    
    # Build history - only include user/assistant pairs
    history = []
    
    # Process history messages (all except the last one)
    if len(conversation_messages) > 1:
        history_messages = conversation_messages[:-1]
        
        # Build user messages list (combining tool results with user messages)
        processed_messages = []
        i = 0
        while i < len(history_messages):
            msg = history_messages[i]
            
            if msg.role == "user":
                content = msg.get_content_text() or "Continue"
                processed_messages.append(("user", content))
                i += 1
            elif msg.role == "assistant":
                # Check if this assistant message contains tool calls
                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                    # Build a description of the tool calls
                    tool_descriptions = []
                    for tc in msg.tool_calls:
                        func_name = tc.function.get("name", "unknown") if isinstance(tc.function, dict) else "unknown"
                        args = tc.function.get("arguments", "{}") if isinstance(tc.function, dict) else "{}"
                        tool_descriptions.append(f"[Called {func_name} with args: {args}]")
                    content = " ".join(tool_descriptions)
                    logger.info(f"ğŸ“Œ Processing assistant message with tool calls: {content}")
                else:
                    content = msg.get_content_text() or "I understand."
                processed_messages.append(("assistant", content))
                i += 1
            elif msg.role == "tool":
                # Combine tool results into the next user message
                tool_content = msg.get_content_text() or "[Tool executed]"
                tool_call_id = getattr(msg, 'tool_call_id', 'unknown')
                
                # Format tool result with ID for tracking
                formatted_tool_result = f"[Tool result for {tool_call_id}]: {tool_content}"
                
                # Look ahead to see if there's a user message
                if i + 1 < len(history_messages) and history_messages[i + 1].role == "user":
                    user_content = history_messages[i + 1].get_content_text() or ""
                    combined_content = f"{formatted_tool_result}\n{user_content}".strip()
                    processed_messages.append(("user", combined_content))
                    i += 2
                else:
                    # Tool result without following user message - add as user message
                    processed_messages.append(("user", formatted_tool_result))
                    i += 1
            else:
                i += 1
        
        # Build history pairs
        i = 0
        while i < len(processed_messages):
            role, content = processed_messages[i]
            
            if role == "user":
                history.append({
                    "userInputMessage": {
                        "content": content,
                        "modelId": codewhisperer_model,
                        "origin": "AI_EDITOR"
                    }
                })
                
                # Look for assistant response
                if i + 1 < len(processed_messages) and processed_messages[i + 1][0] == "assistant":
                    _, assistant_content = processed_messages[i + 1]
                    history.append({
                        "assistantResponseMessage": {
                            "content": assistant_content
                        }
                    })
                    i += 2
                else:
                    # No assistant response, add a placeholder
                    history.append({
                        "assistantResponseMessage": {
                            "content": "I understand."
                        }
                    })
                    i += 1
            elif role == "assistant":
                # Orphaned assistant message
                history.append({
                    "userInputMessage": {
                        "content": "Continue",
                        "modelId": codewhisperer_model,
                        "origin": "AI_EDITOR"
                    }
                })
                history.append({
                    "assistantResponseMessage": {
                        "content": content
                    }
                })
                i += 1
            else:
                i += 1
    
    # Build current message
    current_message = conversation_messages[-1]

    # Handle images in the last message
    images = []
    if isinstance(current_message.content, list):
        for part in current_message.content:
            if part.type == "image_url" and part.image_url:
                try:
                    # è®°å½•åŸå§‹ URL çš„å‰ 50 ä¸ªå­—ç¬¦ï¼Œç”¨äºè°ƒè¯•
                    logger.info(f"ğŸ” å¤„ç†å›¾ç‰‡ URL: {part.image_url.url[:50]}...")
                    
                    # æ£€æŸ¥ URL æ ¼å¼æ˜¯å¦æ­£ç¡®
                    if not part.image_url.url.startswith("data:image/"):
                        logger.error(f"âŒ å›¾ç‰‡ URL æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”è¯¥ä»¥ 'data:image/' å¼€å¤´")
                        continue
                    
                    # Correctly parse the data URI
                    # format: data:image/jpeg;base64,{base64_string}
                    header, encoded_data = part.image_url.url.split(",", 1)
                    
                    # Correctly parse the image format from the mime type
                    # "data:image/jpeg;base64" -> "jpeg"
                    # Use regex to reliably extract image format, e.g., "jpeg" from "data:image/jpeg;base64"
                    match = re.search(r'image/(\w+)', header)
                    if match:
                        image_format = match.group(1)
                        # éªŒè¯ Base64 ç¼–ç æ˜¯å¦æœ‰æ•ˆ
                        try:
                            base64.b64decode(encoded_data)
                            logger.info("âœ… Base64 ç¼–ç éªŒè¯é€šè¿‡")
                        except Exception as e:
                            logger.error(f"âŒ Base64 ç¼–ç æ— æ•ˆ: {e}")
                            continue
                            
                        images.append({
                            "format": image_format,
                            "source": {"bytes": encoded_data}
                        })
                        logger.info(f"ğŸ–¼ï¸ æˆåŠŸå¤„ç†å›¾ç‰‡ï¼Œæ ¼å¼: {image_format}, å¤§å°: {len(encoded_data)} å­—ç¬¦")
                    else:
                        logger.warning(f"âš ï¸ æ— æ³•ä»å¤´éƒ¨ç¡®å®šå›¾ç‰‡æ ¼å¼: {header}")
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†å›¾ç‰‡ URL å¤±è´¥: {str(e)}")

    current_content = current_message.get_content_text()
    
    # Handle different roles for current message
    if current_message.role == "tool":
        # For tool results, format them properly and mark as completed
        tool_result = current_content or '[Tool executed]'
        tool_call_id = getattr(current_message, 'tool_call_id', 'unknown')
        current_content = f"[Tool execution completed for {tool_call_id}]: {tool_result}"
        
        # Check if this tool result follows a tool call in history
        if len(conversation_messages) > 1:
            prev_message = conversation_messages[-2]
            if prev_message.role == "assistant" and hasattr(prev_message, 'tool_calls') and prev_message.tool_calls:
                # Find the corresponding tool call
                for tc in prev_message.tool_calls:
                    if tc.id == tool_call_id:
                        func_name = tc.function.get("name", "unknown") if isinstance(tc.function, dict) else "unknown"
                        current_content = f"[Completed execution of {func_name}]: {tool_result}"
                        break
    elif current_message.role == "assistant":
        # If last message is from assistant with tool calls, format it appropriately
        if hasattr(current_message, 'tool_calls') and current_message.tool_calls:
            tool_descriptions = []
            for tc in current_message.tool_calls:
                func_name = tc.function.get("name", "unknown") if isinstance(tc.function, dict) else "unknown"
                tool_descriptions.append(f"Continue after calling {func_name}")
            current_content = "; ".join(tool_descriptions)
        else:
            current_content = "Continue the conversation"
    
    # Ensure current message has content
    if not current_content:
        current_content = "Continue"
    
    # Add system prompt to current message
    if system_prompt:
        current_content = f"{system_prompt}\n\n{current_content}"
    
    # Build request
    codewhisperer_request = {
        "profileArn": PROFILE_ARN,
        "conversationState": {
            "chatTriggerType": "MANUAL",
            "conversationId": conversation_id,
            "currentMessage": {
                "userInputMessage": {
                    "content": current_content,
                    "modelId": codewhisperer_model,
                    "origin": "AI_EDITOR"
                }
            },
            "history": history
        }
    }
    
    # Add context for tools
    user_input_message_context = {}
    if request.tools:
        user_input_message_context["tools"] = [
            {
                "toolSpecification": {
                    "name": tool.function.name,
                    "description": tool.function.description or "",
                    "inputSchema": {"json": tool.function.parameters or {}}
                }
            } for tool in request.tools
        ]
    
    # æ ¹æ®æ–‡æ¡£ï¼Œimages åº”è¯¥æ˜¯ userInputMessage çš„ç›´æ¥å­å­—æ®µï¼Œè€Œä¸æ˜¯åœ¨ userInputMessageContext ä¸­
    if images:
        # ç›´æ¥æ·»åŠ åˆ° userInputMessage ä¸­
        codewhisperer_request["conversationState"]["currentMessage"]["userInputMessage"]["images"] = images
        logger.info(f"ğŸ“Š æ·»åŠ äº† {len(images)} ä¸ªå›¾ç‰‡åˆ° userInputMessage ä¸­")
        for i, img in enumerate(images):
            logger.info(f"  - å›¾ç‰‡ {i+1}: æ ¼å¼={img['format']}, å¤§å°={len(img['source']['bytes'])} å­—ç¬¦")
            # è®°å½•å›¾ç‰‡æ•°æ®çš„å‰20ä¸ªå­—ç¬¦ï¼Œç”¨äºè°ƒè¯•
            logger.info(f"  - å›¾ç‰‡æ•°æ®å‰20å­—ç¬¦: {img['source']['bytes'][:20]}...")
        logger.info(f"âœ… æˆåŠŸæ·»åŠ  images åˆ° userInputMessage ä¸­")

    if user_input_message_context:
        codewhisperer_request["conversationState"]["currentMessage"]["userInputMessage"]["userInputMessageContext"] = user_input_message_context
        logger.info(f"âœ… æˆåŠŸæ·»åŠ  userInputMessageContext åˆ°è¯·æ±‚ä¸­")
    
    # åˆ›å»ºä¸€ä¸ªç”¨äºæ—¥å¿—è®°å½•çš„è¯·æ±‚å‰¯æœ¬ï¼Œé¿å…è®°å½•å®Œæ•´çš„å›¾ç‰‡æ•°æ®
    log_request = copy.deepcopy(codewhisperer_request)
    # æ£€æŸ¥ images æ˜¯å¦åœ¨ userInputMessage ä¸­
    if "images" in log_request.get("conversationState", {}).get("currentMessage", {}).get("userInputMessage", {}):
        for img in log_request["conversationState"]["currentMessage"]["userInputMessage"]["images"]:
            if "bytes" in img.get("source", {}):
                img["source"]["bytes"] = img["source"]["bytes"][:20] + "..." # åªè®°å½•å‰20ä¸ªå­—ç¬¦
    
    logger.info(f"ğŸ”„ COMPLETE CODEWHISPERER REQUEST: {json.dumps(log_request, indent=2)}")
    return codewhisperer_request
# AWS Event Stream Parser (from version 2)
class CodeWhispererStreamParser:
    def __init__(self):
        self.buffer = b''
        self.error_count = 0
        self.max_errors = 5

    def parse(self, chunk: bytes) -> List[Dict[str, Any]]:
        """è§£æAWSäº‹ä»¶æµæ ¼å¼çš„æ•°æ®å—"""
        self.buffer += chunk
        logger.debug(f"Parser received {len(chunk)} bytes. Buffer size: {len(self.buffer)}")
        events = []
        
        if len(self.buffer) < 12:
            return []
            
        while len(self.buffer) >= 12:
            try:
                header_bytes = self.buffer[0:8]
                total_len, header_len = struct.unpack('>II', header_bytes)
                
                # å®‰å…¨æ£€æŸ¥
                if total_len > 2000000 or header_len > 2000000:
                    logger.error(f"Unreasonable header values: total_len={total_len}, header_len={header_len}")
                    self.buffer = self.buffer[8:]
                    self.error_count += 1
                    if self.error_count > self.max_errors:
                        logger.error("Too many parsing errors, clearing buffer")
                        self.buffer = b''
                    continue

                # ç­‰å¾…å®Œæ•´å¸§
                if len(self.buffer) < total_len:
                    break

                # æå–å®Œæ•´å¸§
                frame = self.buffer[:total_len]
                self.buffer = self.buffer[total_len:]

                # æå–æœ‰æ•ˆè½½è·
                payload_start = 8 + header_len
                payload_end = total_len - 4  # å‡å»å°¾éƒ¨CRC
                
                if payload_start >= payload_end or payload_end > len(frame):
                    logger.error(f"Invalid payload bounds")
                    continue
                    
                payload = frame[payload_start:payload_end]
                
                # è§£ç æœ‰æ•ˆè½½è·
                try:
                    payload_str = payload.decode('utf-8', errors='ignore')
                    
                    # å°è¯•è§£æJSON
                    json_start_index = payload_str.find('{')
                    if json_start_index != -1:
                        json_payload = payload_str[json_start_index:]
                        event_data = json.loads(json_payload)
                        events.append(event_data)
                        logger.debug(f"Successfully parsed event: {event_data}")
                except json.JSONDecodeError as e:
                    logger.error(f"JSON decode error: {e}")
                    continue

            except struct.error as e:
                logger.error(f"Struct unpack error: {e}")
                self.buffer = self.buffer[1:]
                self.error_count += 1
                if self.error_count > self.max_errors:
                    logger.error("Too many parsing errors, clearing buffer")
                    self.buffer = b''
            except Exception as e:
                logger.error(f"Unexpected error during parsing: {str(e)}")
                self.buffer = self.buffer[1:]
                self.error_count += 1
                if self.error_count > self.max_errors:
                    logger.error("Too many parsing errors, clearing buffer")
                    self.buffer = b''
        
        if events:
            self.error_count = 0
            
        return events

# Simple fallback parser for basic responses
class SimpleResponseParser:
    @staticmethod
    def parse_event_stream_to_json(raw_data: bytes) -> Dict[str, Any]:
        """Simple parser for fallback (from version 1)"""
        try:
            if isinstance(raw_data, bytes):
                raw_str = raw_data.decode('utf-8', errors='ignore')
            else:
                raw_str = str(raw_data)
            
            # Method 1: Look for JSON objects with content field
            json_pattern = r'\{[^{}]*"content"[^{}]*\}'
            matches = re.findall(json_pattern, raw_str, re.DOTALL)
            
            if matches:
                content_parts = []
                for match in matches:
                    try:
                        data = json.loads(match)
                        if 'content' in data and data['content']:
                            content_parts.append(data['content'])
                    except json.JSONDecodeError:
                        continue
                if content_parts:
                    full_content = ''.join(content_parts)
                    return {
                        "content": full_content, 
                        "tokens": len(full_content.split())
                    }
            
            # Method 2: Extract readable text
            clean_text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', raw_str)
            clean_text = re.sub(r':event-type[^:]*:[^:]*:[^:]*:', '', clean_text)
            clean_text = re.sub(r':content-type[^:]*:[^:]*:[^:]*:', '', clean_text)
            
            meaningful_text = re.sub(r'[^\w\s\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff.,!?;:()"\'-]', '', clean_text)
            meaningful_text = re.sub(r'\s+', ' ', meaningful_text).strip()
            
            if meaningful_text and len(meaningful_text) > 5:
                return {
                    "content": meaningful_text, 
                    "tokens": len(meaningful_text.split())
                }
            
            return {"content": "No readable content found", "tokens": 0}
            
        except Exception as e:
            return {"content": f"Error parsing response: {str(e)}", "tokens": 0}

# API call to CodeWhisperer
async def call_kiro_api(request: ChatCompletionRequest):
    """Make API call to Kiro/CodeWhisperer with token refresh handling"""
    token = token_manager.get_token()
    if not token:
        raise HTTPException(
            status_code=401, 
            detail={
                "error": {
                    "message": "No access token available",
                    "type": "authentication_error",
                    "param": None,
                    "code": "invalid_api_key"
                }
            }
        )
    
    request_data = build_codewhisperer_request(request)
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "Accept": "text/event-stream" if request.stream else "application/json"
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                KIRO_BASE_URL,
                headers=headers,
                json=request_data,
                timeout=120
            )
            
            logger.info(f"ğŸ“¤ RESPONSE STATUS: {response.status_code}")
            
            if response.status_code == 403:
                logger.info("æ”¶åˆ°403å“åº”ï¼Œå°è¯•åˆ·æ–°token...")
                new_token = await token_manager.refresh_tokens()
                if new_token:
                    headers["Authorization"] = f"Bearer {new_token}"
                    response = await client.post(
                        KIRO_BASE_URL,
                        headers=headers,
                        json=request_data,
                        timeout=120
                    )
                    logger.info(f"ğŸ“¤ RETRY RESPONSE STATUS: {response.status_code}")
                else:
                    raise HTTPException(status_code=401, detail="Token refresh failed")
            
            if response.status_code == 429:
                raise HTTPException(
                    status_code=429,
                    detail={
                        "error": {
                            "message": "Rate limit exceeded",
                            "type": "rate_limit_error",
                            "param": None,
                            "code": "rate_limit_exceeded"
                        }
                    }
                )
            
            response.raise_for_status()
            return response
            
    except httpx.HTTPStatusError as e:
        logger.error(f"HTTP ERROR: {e.response.status_code} - {e.response.text}")
        raise HTTPException(
            status_code=503,
            detail={
                "error": {
                    "message": f"API call failed: {str(e)}",
                    "type": "api_error",
                    "param": None,
                    "code": "api_error"
                }
            }
        )
    except Exception as e:
        logger.error(f"API call failed: {str(e)}")
        raise HTTPException(
            status_code=503,
            detail={
                "error": {
                    "message": f"API call failed: {str(e)}",
                    "type": "api_error",
                    "param": None,
                    "code": "api_error"
                }
            }
        )

# Utility functions
def estimate_tokens(text: str) -> int:
    """Rough token estimation"""
    return max(1, len(text) // 4)

def create_usage_stats(prompt_text: str, completion_text: str) -> Usage:
    """Create usage statistics"""
    prompt_tokens = estimate_tokens(prompt_text)
    completion_tokens = estimate_tokens(completion_text)
    return Usage(
        prompt_tokens=prompt_tokens,
        completion_tokens=completion_tokens,
        total_tokens=prompt_tokens + completion_tokens
    )

# API endpoints
@app.get("/v1/models")
async def list_models(api_key: str = Depends(verify_api_key)):
    """List available models"""
    return {
        "object": "list",
        "data": [
            {
                "id": model_id,
                "object": "model",
                "created": int(time.time()),
                "owned_by": "ki2api"
            }
            for model_id in MODEL_MAP.keys()
        ]
    }

@app.post("/v1/chat/completions")
async def create_chat_completion(
    request: ChatCompletionRequest,
    api_key: str = Depends(verify_api_key)
):
    """Create a chat completion"""
    logger.info(f"ğŸ“¥ COMPLETE REQUEST: {request.model_dump_json(indent=2)}")

    # Validate messages have content
    for i, msg in enumerate(request.messages):
        if msg.content is None and msg.role != "assistant":
            logger.warning(f"Message {i} with role '{msg.role}' has None content")

    if request.model not in MODEL_MAP:
        raise HTTPException(
            status_code=400,
            detail={
                "error": {
                    "message": f"The model '{request.model}' does not exist or you do not have access to it.",
                    "type": "invalid_request_error",
                    "param": "model",
                    "code": "model_not_found"
                }
            }
        )

    # æ ¹æ®è¯·æ±‚ç±»å‹è°ƒç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°ï¼Œå®ç°çœŸæ­£çš„æµå¼/éæµå¼å¤„ç†
    if request.stream:
        logger.info("ğŸŒŠ ä½¿ç”¨çœŸæ­£çš„æµå¼å¤„ç†")
        return await create_streaming_response(request)
    else:
        logger.info("ğŸ“„ ä½¿ç”¨éæµå¼å¤„ç†")
        return await create_non_streaming_response(request)


async def convert_to_streaming_response(response: ChatCompletionResponse):
    """
    [å·²åºŸå¼ƒ] å°†éæµå¼å“åº”è½¬æ¢ä¸ºæµå¼æ ¼å¼è¿”å›
    æ­¤å‡½æ•°ä¸å†ä½¿ç”¨ï¼Œå› ä¸ºç°åœ¨ç›´æ¥ä½¿ç”¨ create_streaming_response å®ç°çœŸæ­£çš„æµå¼å¤„ç†
    """
    async def generate_stream():
        # ä½¿ç”¨åŸå“åº”çš„IDå’Œæ—¶é—´æˆ³
        response_id = response.id
        created = response.created
        model = response.model
        
        # å‘é€åˆå§‹å— - role
        initial_chunk = ChatCompletionStreamResponse(
            id=response_id,
            model=model,
            created=created,
            choices=[StreamChoice(
                index=0,
                delta={"role": "assistant"},
                finish_reason=None
            )]
        )
        yield f"data: {initial_chunk.model_dump_json(exclude_none=True)}\n\n"
        
        # è·å–å“åº”æ¶ˆæ¯
        if response.choices and len(response.choices) > 0:
            message = response.choices[0].message
            
            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå‘é€å·¥å…·è°ƒç”¨
            if message.tool_calls:
                for i, tool_call in enumerate(message.tool_calls):
                    # å‘é€å®Œæ•´çš„å·¥å…·è°ƒç”¨ä½œä¸ºä¸€ä¸ªå—
                    tool_chunk = ChatCompletionStreamResponse(
                        id=response_id,
                        model=model,
                        created=created,
                        choices=[StreamChoice(
                            index=0,
                            delta={
                                "tool_calls": [{
                                    "index": i,
                                    "id": tool_call.id,
                                    "type": tool_call.type,
                                    "function": tool_call.function
                                }]
                            },
                            finish_reason=None
                        )]
                    )
                    yield f"data: {tool_chunk.model_dump_json(exclude_none=True)}\n\n"
            
            # å¦‚æœæœ‰å†…å®¹ï¼Œåˆ†å—å‘é€å†…å®¹
            elif message.content:
                # å°†å†…å®¹åˆ†æˆè¾ƒå°çš„å—ä»¥æ¨¡æ‹Ÿæµå¼ä¼ è¾“
                content = message.content
                chunk_size = 50  # æ¯ä¸ªå—çš„å­—ç¬¦æ•°
                
                for i in range(0, len(content), chunk_size):
                    chunk_text = content[i:i + chunk_size]
                    content_chunk = ChatCompletionStreamResponse(
                        id=response_id,
                        model=model,
                        created=created,
                        choices=[StreamChoice(
                            index=0,
                            delta={"content": chunk_text},
                            finish_reason=None
                        )]
                    )
                    yield f"data: {content_chunk.model_dump_json(exclude_none=True)}\n\n"
                    # æ·»åŠ å°å»¶è¿Ÿä»¥æ¨¡æ‹ŸçœŸå®çš„æµå¼ä¼ è¾“
                    await asyncio.sleep(0.01)
            
            # å‘é€ç»“æŸå—
            finish_reason = response.choices[0].finish_reason
            end_chunk = ChatCompletionStreamResponse(
                id=response_id,
                model=model,
                created=created,
                choices=[StreamChoice(
                    index=0,
                    delta={},
                    finish_reason=finish_reason
                )]
            )
            yield f"data: {end_chunk.model_dump_json(exclude_none=True)}\n\n"
        
        # å‘é€æµç»“æŸæ ‡è®°
        yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream"
        }
    )

async def create_non_streaming_response(request: ChatCompletionRequest):
    """
    Handles non-streaming chat completion requests.
    It fetches the complete response from CodeWhisperer, parses it using
    CodeWhispererStreamParser, and constructs a single OpenAI-compatible
    ChatCompletionResponse. This version correctly handles tool calls by
    parsing both structured event data and bracket format in text.
    """
    try:
        logger.info("ğŸš€ å¼€å§‹éæµå¼å“åº”ç”Ÿæˆ...")
        response = await call_kiro_api(request)
        
        # æ·»åŠ è¯¦ç»†çš„åŸå§‹å“åº”æ—¥å¿—
        logger.info(f"ğŸ“¤ CodeWhispererå“åº”çŠ¶æ€ç : {response.status_code}")
        logger.info(f"ğŸ“¤ å“åº”å¤´: {dict(response.headers)}")
        logger.info(f"ğŸ“¤ åŸå§‹å“åº”ä½“é•¿åº¦: {len(response.content)} bytes")
        
        # è·å–åŸå§‹å“åº”æ–‡æœ¬ç”¨äºå·¥å…·è°ƒç”¨æ£€æµ‹
        raw_response_text = ""
        try:
            raw_response_text = response.content.decode('utf-8', errors='ignore')
            logger.info(f"ğŸ” åŸå§‹å“åº”æ–‡æœ¬é•¿åº¦: {len(raw_response_text)}")
            logger.info(f"ğŸ” åŸå§‹å“åº”é¢„è§ˆ(å‰1000å­—ç¬¦): {raw_response_text[:1000]}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨æ ‡è®°
            if "[Called" in raw_response_text:
                logger.info("âœ… åŸå§‹å“åº”ä¸­å‘ç° [Called æ ‡è®°")
                called_positions = [m.start() for m in re.finditer(r'\[Called', raw_response_text)]
                logger.info(f"ğŸ¯ [Called å‡ºç°ä½ç½®: {called_positions}")
            else:
                logger.info("âŒ åŸå§‹å“åº”ä¸­æœªå‘ç° [Called æ ‡è®°")
                
        except Exception as e:
            logger.error(f"âŒ è§£ç åŸå§‹å“åº”å¤±è´¥: {e}")
        
        # ä½¿ç”¨ CodeWhispererStreamParser ä¸€æ¬¡æ€§è§£ææ•´ä¸ªå“åº”ä½“
        parser = CodeWhispererStreamParser()
        events = parser.parse(response.content)
        
        full_response_text = ""
        tool_calls = []
        current_tool_call_dict = None

        logger.info(f"ğŸ”„ è§£æåˆ° {len(events)} ä¸ªäº‹ä»¶ï¼Œå¼€å§‹å¤„ç†...")
        
        # è®°å½•æ¯ä¸ªäº‹ä»¶çš„è¯¦ç»†ä¿¡æ¯
        for i, event in enumerate(events):
            logger.info(f"ğŸ“‹ äº‹ä»¶ {i}: {event}")

        for event in events:
            # ä¼˜å…ˆå¤„ç†ç»“æ„åŒ–å·¥å…·è°ƒç”¨äº‹ä»¶
            if "name" in event and "toolUseId" in event:
                logger.info(f"ğŸ”§ å‘ç°ç»“æ„åŒ–å·¥å…·è°ƒç”¨äº‹ä»¶: {event}")
                # å¦‚æœæ˜¯æ–°çš„å·¥å…·è°ƒç”¨ï¼Œåˆ™åˆå§‹åŒ–
                if not current_tool_call_dict:
                    current_tool_call_dict = {
                        "id": event.get("toolUseId"),
                        "type": "function",
                        "function": {
                            "name": event.get("name"),
                            "arguments": ""
                        }
                    }
                    logger.info(f"ğŸ†• å¼€å§‹è§£æå·¥å…·è°ƒç”¨: {current_tool_call_dict['function']['name']}")

                # ç´¯ç§¯å‚æ•°
                if "input" in event:
                    current_tool_call_dict["function"]["arguments"] += event.get("input", "")
                    logger.info(f"ğŸ“ ç´¯ç§¯å‚æ•°: {event.get('input', '')}")

                # å·¥å…·è°ƒç”¨ç»“æŸ
                if event.get("stop"):
                    logger.info(f"âœ… å®Œæˆå·¥å…·è°ƒç”¨: {current_tool_call_dict['function']['name']}")
                    # éªŒè¯å¹¶æ ‡å‡†åŒ–å‚æ•°ä¸ºJSONå­—ç¬¦ä¸²
                    try:
                        args = json.loads(current_tool_call_dict["function"]["arguments"])
                        current_tool_call_dict["function"]["arguments"] = json.dumps(args, ensure_ascii=False)
                        logger.info(f"âœ… å·¥å…·è°ƒç”¨å‚æ•°éªŒè¯æˆåŠŸ")
                    except json.JSONDecodeError as e:
                        logger.warning(f"âš ï¸ å·¥å…·è°ƒç”¨çš„å‚æ•°ä¸æ˜¯æœ‰æ•ˆçš„JSON: {current_tool_call_dict['function']['arguments']}")
                        logger.warning(f"âš ï¸ JSONé”™è¯¯: {e}")
                    
                    tool_calls.append(ToolCall(**current_tool_call_dict))
                    current_tool_call_dict = None # é‡ç½®ä»¥å¤‡ä¸‹ä¸€ä¸ª
            
            # å¤„ç†æ™®é€šæ–‡æœ¬å†…å®¹äº‹ä»¶
            elif "content" in event:
                content = event.get("content", "")
                full_response_text += content
                logger.info(f"ğŸ“„ æ·»åŠ æ–‡æœ¬å†…å®¹: {content[:100]}...")

        # å¦‚æœæµåœ¨å·¥å…·è°ƒç”¨ä¸­é—´æ„å¤–ç»“æŸï¼Œä¹Ÿå°†å…¶æ·»åŠ 
        if current_tool_call_dict:
            logger.warning("âš ï¸ å“åº”æµåœ¨å·¥å…·è°ƒç”¨ç»“æŸå‰ç»ˆæ­¢ï¼Œä»å°è¯•æ·»åŠ ã€‚")
            tool_calls.append(ToolCall(**current_tool_call_dict))

        logger.info(f"ğŸ“Š äº‹ä»¶å¤„ç†å®Œæˆ - æ–‡æœ¬é•¿åº¦: {len(full_response_text)}, ç»“æ„åŒ–å·¥å…·è°ƒç”¨: {len(tool_calls)}")

        # æ£€æŸ¥è§£æåæ–‡æœ¬ä¸­çš„ bracket æ ¼å¼å·¥å…·è°ƒç”¨
        logger.info("ğŸ” å¼€å§‹æ£€æŸ¥è§£æåæ–‡æœ¬ä¸­çš„bracketæ ¼å¼å·¥å…·è°ƒç”¨...")
        bracket_tool_calls = parse_bracket_tool_calls(full_response_text)
        if bracket_tool_calls:
            logger.info(f"âœ… åœ¨è§£æåæ–‡æœ¬ä¸­å‘ç° {len(bracket_tool_calls)} ä¸ª bracket æ ¼å¼å·¥å…·è°ƒç”¨")
            tool_calls.extend(bracket_tool_calls)
            
            # ä»å“åº”æ–‡æœ¬ä¸­ç§»é™¤å·¥å…·è°ƒç”¨æ–‡æœ¬
            for tc in bracket_tool_calls:
                # æ„å»ºç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…è¿™ä¸ªç‰¹å®šçš„å·¥å…·è°ƒç”¨
                func_name = tc.function.get("name", "unknown")
                # è½¬ä¹‰å‡½æ•°åä¸­çš„ç‰¹æ®Šå­—ç¬¦
                escaped_name = re.escape(func_name)
                # åŒ¹é… [Called FunctionName with args: {...}]
                pattern = r'\[Called\s+' + escaped_name + r'\s+with\s+args:\s*\{[^}]*(?:\{[^}]*\}[^}]*)*\}\s*\]'
                full_response_text = re.sub(pattern, '', full_response_text, flags=re.DOTALL)
            
            # æ¸…ç†å¤šä½™çš„ç©ºç™½
            full_response_text = re.sub(r'\s+', ' ', full_response_text).strip()

        # å…³é”®ä¿®å¤ï¼šæ£€æŸ¥åŸå§‹å“åº”ä¸­çš„ bracket æ ¼å¼å·¥å…·è°ƒç”¨
        logger.info("ğŸ” å¼€å§‹æ£€æŸ¥åŸå§‹å“åº”ä¸­çš„bracketæ ¼å¼å·¥å…·è°ƒç”¨...")
        raw_bracket_tool_calls = parse_bracket_tool_calls(raw_response_text)
        if raw_bracket_tool_calls and isinstance(raw_bracket_tool_calls, list):
            logger.info(f"âœ… åœ¨åŸå§‹å“åº”ä¸­å‘ç° {len(raw_bracket_tool_calls)} ä¸ª bracket æ ¼å¼å·¥å…·è°ƒç”¨")
            tool_calls.extend(raw_bracket_tool_calls)
        else:
            logger.info("âŒ åŸå§‹å“åº”ä¸­æœªå‘ç°bracketæ ¼å¼å·¥å…·è°ƒç”¨")

        # å»é‡å·¥å…·è°ƒç”¨
        logger.info(f"ğŸ”„ å»é‡å‰å·¥å…·è°ƒç”¨æ•°é‡: {len(tool_calls)}")
        unique_tool_calls = deduplicate_tool_calls(tool_calls)
        logger.info(f"ğŸ”„ å»é‡åå·¥å…·è°ƒç”¨æ•°é‡: {len(unique_tool_calls)}")

        # æ ¹æ®æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨æ¥æ„å»ºå“åº”
        if unique_tool_calls:
            logger.info(f"ğŸ”§ æ„å»ºå·¥å…·è°ƒç”¨å“åº”ï¼ŒåŒ…å« {len(unique_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
            for i, tc in enumerate(unique_tool_calls):
                logger.info(f"ğŸ”§ å·¥å…·è°ƒç”¨ {i}: {tc.function.get('name', 'unknown')}")
            
            response_message = ResponseMessage(
                role="assistant",
                content=None,  # OpenAIè§„èŒƒï¼šå½“æœ‰tool_callsæ—¶ï¼Œcontentå¿…é¡»ä¸ºNone
                tool_calls=unique_tool_calls
            )
            finish_reason = "tool_calls"
        else:
            logger.info("ğŸ“„ æ„å»ºæ™®é€šæ–‡æœ¬å“åº”")
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨æ¸…ç†åçš„æ–‡æœ¬
            content = full_response_text.strip() if full_response_text.strip() else "I understand."
            logger.info(f"ğŸ“„ æœ€ç»ˆæ–‡æœ¬å†…å®¹: {content[:200]}...")
            
            response_message = ResponseMessage(
                role="assistant",
                content=content
            )
            finish_reason = "stop"

        choice = Choice(
            index=0,
            message=response_message,
            finish_reason=finish_reason
        )

        usage = create_usage_stats(
            prompt_text=" ".join([msg.get_content_text() for msg in request.messages]),
            completion_text=full_response_text if not unique_tool_calls else ""
        )

        chat_response = ChatCompletionResponse(
            model=request.model,
            choices=[choice],
            usage=usage
        )
        
        logger.info(f"ğŸ“¤ æœ€ç»ˆéæµå¼å“åº”æ„å»ºå®Œæˆ")
        logger.info(f"ğŸ“¤ å“åº”ç±»å‹: {'å·¥å…·è°ƒç”¨' if unique_tool_calls else 'æ–‡æœ¬å†…å®¹'}")
        logger.info(f"ğŸ“¤ å®Œæ•´å“åº”: {chat_response.model_dump_json(indent=2, exclude_none=True)}")
        return chat_response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ éæµå¼å“åº”å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail={
                "error": {
                    "message": f"Internal server error: {str(e)}",
                    "type": "internal_server_error",
                    "param": None,
                    "code": "internal_error"
                }
            }
        )

async def create_streaming_response(request: ChatCompletionRequest):
    """
    Handles streaming chat completion requests.
    çœŸæ­£çš„æµå¼å¤„ç†ï¼šåœ¨åŒä¸€ä¸ªä¸Šä¸‹æ–‡ä¸­ä¿æŒ HTTP è¿æ¥ï¼Œè¾¹æ”¶è¾¹æ¨ã€‚
    """
    
    async def generate_stream():
        response_id = f"chatcmpl-{uuid.uuid4()}"
        created = int(time.time())
        parser = CodeWhispererStreamParser()

        # --- çŠ¶æ€å˜é‡ ---
        is_in_tool_call = False
        sent_role = False
        current_tool_call_index = 0
        streamed_tool_calls_count = 0
        content_buffer = ""
        incomplete_tool_call = ""

        # å‡†å¤‡è¯·æ±‚
        token = token_manager.get_token()
        if not token:
            yield f"data: {json.dumps({'error': {'message': 'No access token available', 'type': 'authentication_error'}})}\n\n"
            return

        request_data = build_codewhisperer_request(request)
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json",
            "Accept": "text/event-stream"
        }

        # ä½¿ç”¨ httpx.Timeout åˆ†ç¦»è¿æ¥è¶…æ—¶å’Œè¯»å–è¶…æ—¶ï¼Œé¿å…é•¿å¯¹è¯è¢«æˆªæ–­
        timeout = httpx.Timeout(connect=30.0, read=None, write=30.0, pool=30.0)

        try:
            async with httpx.AsyncClient(timeout=timeout) as client:
                # æ”¯æŒ 403 é‡è¯•çš„å¾ªç¯
                max_retries = 2
                for attempt in range(max_retries):
                    async with client.stream("POST", KIRO_BASE_URL, headers=headers, json=request_data) as response:
                        logger.info(f"ğŸ“¤ STREAM RESPONSE STATUS: {response.status_code} (attempt {attempt + 1})")

                        # å¤„ç† 403 - åˆ·æ–° token å¹¶é‡è¯•
                        if response.status_code == 403 and attempt < max_retries - 1:
                            logger.info("æ”¶åˆ°403å“åº”ï¼Œå°è¯•åˆ·æ–°token...")
                            new_token = await token_manager.refresh_tokens()
                            if new_token:
                                headers["Authorization"] = f"Bearer {new_token}"
                                continue  # é‡è¯•
                            else:
                                yield f"data: {json.dumps({'error': {'message': 'Token refresh failed', 'type': 'authentication_error'}})}\n\n"
                                return

                        if response.status_code == 429:
                            yield f"data: {json.dumps({'error': {'message': 'Rate limit exceeded', 'type': 'rate_limit_error'}})}\n\n"
                            return

                        if response.status_code != 200:
                            yield f"data: {json.dumps({'error': {'message': f'API error: {response.status_code}', 'type': 'api_error'}})}\n\n"
                            return

                        # çœŸæ­£çš„æµå¼å¤„ç†ï¼šè¾¹æ”¶è¾¹æ¨
                        async for chunk in response.aiter_bytes():
                            events = parser.parse(chunk)
                            
                            for event in events:
                                # --- å¤„ç†ç»“æ„åŒ–å·¥å…·è°ƒç”¨äº‹ä»¶ ---
                                if "name" in event and "toolUseId" in event:
                                    logger.info(f"ğŸ¯ STREAM: Found structured tool call event: {event}")
                                    if not is_in_tool_call:
                                        is_in_tool_call = True
                                        
                                        delta_start = {
                                            "tool_calls": [{
                                                "index": current_tool_call_index,
                                                "id": event.get("toolUseId"),
                                                "type": "function",
                                                "function": {"name": event.get("name"), "arguments": ""}
                                            }]
                                        }
                                        if not sent_role:
                                            delta_start["role"] = "assistant"
                                            sent_role = True

                                        start_chunk = ChatCompletionStreamResponse(
                                            id=response_id, model=request.model, created=created,
                                            choices=[StreamChoice(index=0, delta=delta_start)]
                                        )
                                        yield f"data: {start_chunk.model_dump_json(exclude_none=True)}\n\n"

                                    if "input" in event:
                                        arg_chunk_str = event.get("input", "")
                                        if arg_chunk_str:
                                            arg_chunk_delta = {
                                                "tool_calls": [{
                                                    "index": current_tool_call_index,
                                                    "function": {"arguments": arg_chunk_str}
                                                }]
                                            }
                                            arg_chunk_resp = ChatCompletionStreamResponse(
                                                id=response_id, model=request.model, created=created,
                                                choices=[StreamChoice(index=0, delta=arg_chunk_delta)]
                                            )
                                            yield f"data: {arg_chunk_resp.model_dump_json(exclude_none=True)}\n\n"

                                    if event.get("stop"):
                                        is_in_tool_call = False
                                        current_tool_call_index += 1
                                        streamed_tool_calls_count += 1

                                # --- å¤„ç†æ™®é€šæ–‡æœ¬å†…å®¹äº‹ä»¶ ---
                                elif "content" in event and not is_in_tool_call:
                                    content_text = event.get("content", "")
                                    if content_text:
                                        # å¦‚æœæœ‰ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨ï¼Œå…ˆåˆå¹¶å†å¤„ç†
                                        if incomplete_tool_call:
                                            content_buffer = incomplete_tool_call + content_text
                                            incomplete_tool_call = ""
                                        else:
                                            content_buffer += content_text
                                        
                                        # å¤„ç† bracket æ ¼å¼çš„å·¥å…·è°ƒç”¨
                                        while True:
                                            called_start = content_buffer.find("[Called")
                                            
                                            if called_start == -1:
                                                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå‘é€æ‰€æœ‰å†…å®¹
                                                if content_buffer:
                                                    delta_content = {"content": content_buffer}
                                                    if not sent_role:
                                                        delta_content["role"] = "assistant"
                                                        sent_role = True
                                                    
                                                    content_chunk = ChatCompletionStreamResponse(
                                                        id=response_id, model=request.model, created=created,
                                                        choices=[StreamChoice(index=0, delta=delta_content)]
                                                    )
                                                    yield f"data: {content_chunk.model_dump_json(exclude_none=True)}\n\n"
                                                    content_buffer = ""
                                                break
                                            
                                            # å‘é€ [Called ä¹‹å‰çš„æ–‡æœ¬
                                            if called_start > 0:
                                                text_before = content_buffer[:called_start]
                                                if text_before.strip():
                                                    delta_content = {"content": text_before}
                                                    if not sent_role:
                                                        delta_content["role"] = "assistant"
                                                        sent_role = True
                                                    
                                                    content_chunk = ChatCompletionStreamResponse(
                                                        id=response_id, model=request.model, created=created,
                                                        choices=[StreamChoice(index=0, delta=delta_content)]
                                                    )
                                                    yield f"data: {content_chunk.model_dump_json(exclude_none=True)}\n\n"
                                            
                                            # æŸ¥æ‰¾å¯¹åº”çš„ç»“æŸ ]
                                            remaining_text = content_buffer[called_start:]
                                            bracket_end = find_matching_bracket(remaining_text, 0)
                                            
                                            if bracket_end == -1:
                                                # å·¥å…·è°ƒç”¨ä¸å®Œæ•´ï¼Œä¿ç•™ç­‰å¾…æ›´å¤šæ•°æ®
                                                incomplete_tool_call = remaining_text
                                                content_buffer = ""
                                                break
                                            
                                            # æå–å®Œæ•´çš„å·¥å…·è°ƒç”¨
                                            tool_call_text = remaining_text[:bracket_end + 1]
                                            parsed_call = parse_single_tool_call(tool_call_text)
                                            
                                            if parsed_call:
                                                delta_tool = {
                                                    "tool_calls": [{
                                                        "index": current_tool_call_index,
                                                        "id": parsed_call.id,
                                                        "type": "function",
                                                        "function": {
                                                            "name": parsed_call.function["name"],
                                                            "arguments": parsed_call.function["arguments"]
                                                        }
                                                    }]
                                                }
                                                if not sent_role:
                                                    delta_tool["role"] = "assistant"
                                                    sent_role = True
                                                
                                                logger.info(f"ğŸ“¤ STREAM: Sending tool call: {parsed_call.function['name']}")
                                                tool_chunk = ChatCompletionStreamResponse(
                                                    id=response_id, model=request.model, created=created,
                                                    choices=[StreamChoice(index=0, delta=delta_tool)]
                                                )
                                                yield f"data: {tool_chunk.model_dump_json(exclude_none=True)}\n\n"
                                                current_tool_call_index += 1
                                                streamed_tool_calls_count += 1
                                            
                                            # æ›´æ–°ç¼“å†²åŒºï¼Œç»§ç»­å¤„ç†å‰©ä½™å†…å®¹
                                            content_buffer = remaining_text[bracket_end + 1:]
                                            incomplete_tool_call = ""

                        # æµç»“æŸåå¤„ç†å‰©ä½™å†…å®¹
                        if incomplete_tool_call:
                            content_buffer = incomplete_tool_call + content_buffer
                            incomplete_tool_call = ""
                            
                            called_start = content_buffer.find("[Called")
                            if called_start == 0:
                                bracket_end = find_matching_bracket(content_buffer, 0)
                                if bracket_end != -1:
                                    tool_call_text = content_buffer[:bracket_end + 1]
                                    parsed_call = parse_single_tool_call(tool_call_text)
                                    
                                    if parsed_call:
                                        delta_tool = {
                                            "tool_calls": [{
                                                "index": current_tool_call_index,
                                                "id": parsed_call.id,
                                                "type": "function",
                                                "function": {
                                                    "name": parsed_call.function["name"],
                                                    "arguments": parsed_call.function["arguments"]
                                                }
                                            }]
                                        }
                                        if not sent_role:
                                            delta_tool["role"] = "assistant"
                                            sent_role = True
                                        
                                        tool_chunk = ChatCompletionStreamResponse(
                                            id=response_id, model=request.model, created=created,
                                            choices=[StreamChoice(index=0, delta=delta_tool)]
                                        )
                                        yield f"data: {tool_chunk.model_dump_json(exclude_none=True)}\n\n"
                                        current_tool_call_index += 1
                                        streamed_tool_calls_count += 1
                                        
                                        content_buffer = content_buffer[bracket_end + 1:]

                        # å‘é€ä»»ä½•å‰©ä½™çš„å†…å®¹
                        if content_buffer.strip():
                            delta_content = {"content": content_buffer}
                            if not sent_role:
                                delta_content["role"] = "assistant"
                                sent_role = True
                            
                            content_chunk = ChatCompletionStreamResponse(
                                id=response_id, model=request.model, created=created,
                                choices=[StreamChoice(index=0, delta=delta_content)]
                            )
                            yield f"data: {content_chunk.model_dump_json(exclude_none=True)}\n\n"

                        # --- æµç»“æŸ ---
                        finish_reason = "tool_calls" if streamed_tool_calls_count > 0 else "stop"
                        logger.info(f"ğŸ STREAM: Completed with {streamed_tool_calls_count} tool calls, finish_reason={finish_reason}")
                        end_chunk = ChatCompletionStreamResponse(
                            id=response_id, model=request.model, created=created,
                            choices=[StreamChoice(index=0, delta={}, finish_reason=finish_reason)]
                        )
                        yield f"data: {end_chunk.model_dump_json(exclude_none=True)}\n\n"
                        
                        yield "data: [DONE]\n\n"
                        return  # æˆåŠŸå®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯

        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP ERROR in stream: {e}")
            yield f"data: {json.dumps({'error': {'message': str(e), 'type': 'api_error'}})}\n\n"
        except Exception as e:
            logger.error(f"Stream error: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'error': {'message': str(e), 'type': 'internal_error'}})}\n\n"

    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream"
        }
    )

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "service": "Ki2API", "version": "3.0.1"}

@app.get("/")
async def root():
    """Root endpoint with service information"""
    return {
        "service": "Ki2API",
        "description": "OpenAI-compatible API for Claude Sonnet 4 via AWS CodeWhisperer",
        "version": "3.0.1",
        "endpoints": {
            "models": "/v1/models",
            "chat": "/v1/chat/completions",
            "health": "/health"
        },
        "features": {
            "streaming": True,
            "tools": True,
            "multiple_models": True,
            "xml_tool_parsing": True,
            "auto_token_refresh": True,
            "null_content_handling": True,
            "tool_call_deduplication": True
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8989)